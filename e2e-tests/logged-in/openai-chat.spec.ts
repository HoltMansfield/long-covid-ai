import { test, expect } from '@playwright/test';

test.describe('OpenAI Chat Integration', () => {
  test('chat interface loads and shows initial AI message', async ({ page }) => {
    // Navigate to chat page (user is already authenticated)
    await page.goto(`${process.env.E2E_URL}/chat`);
    await page.waitForTimeout(2000);
    
    // Verify chat interface elements are present
    await expect(page.locator('h2')).toContainText('Long COVID Support Assistant');
    await expect(page.locator('textarea')).toBeVisible();
    await expect(page.locator('button:has-text("Send")')).toBeVisible();
    
    // Verify initial AI message is shown (since chat starts with crash report interview)
    await expect(page.locator('text=I understand you\'ve experienced a crash')).toBeVisible();
    await expect(page.locator('text=on a scale of 1 to 10')).toBeVisible();
  });

  test('can send a message and receive AI response', async ({ page }) => {
    // Navigate to chat page (user is already authenticated)
    await page.goto(`${process.env.E2E_URL}/chat`);
    await page.waitForTimeout(2000);
    
    // Send a simple test message
    const testMessage = 'Hello, this is a test message';
    const textarea = page.locator('textarea');
    const sendButton = page.locator('button:has-text("Send")');
    
    await textarea.fill(testMessage);
    await sendButton.click();
    
    // Verify user message appears (look for message in chat bubble, not button)
    await expect(page.locator('.bg-blue-500.text-white').filter({ hasText: testMessage })).toBeVisible();
    
    // Wait for AI response (with generous timeout for API call)
    // Look for AI response that's not the loading indicator
    await expect(page.locator('.bg-gray-100').filter({ hasNotText: 'Thinking...' })).toBeVisible({ timeout: 30000 });
    
    // Verify AI response is not empty and doesn't contain error message
    const aiResponse = page.locator('.bg-gray-100').filter({ hasNotText: 'Thinking...' }).last();
    await expect(aiResponse).toBeVisible();
    
    // Check that we don't get the generic error message
    await expect(aiResponse).not.toContainText('I apologize, but I encountered an error');
    
    // Verify the response contains some text (AI should respond with something)
    const responseText = await aiResponse.textContent();
    expect(responseText?.length).toBeGreaterThan(5);
  });

  test('voice input button appears and shows proper states', async ({ page }) => {
    // Navigate to chat page (user is already authenticated)
    await page.goto(`${process.env.E2E_URL}/chat`);
    await page.waitForTimeout(3000); // Wait for hydration and audio support detection
    
    // Check if voice input is supported in this browser/environment
    const voiceButton = page.locator('button:has-text("üé§ Voice")');
    const voiceIndicator = page.locator('text=üé§ Voice input available');
    
    // Voice features should appear after hydration (if supported)
    // Note: In headless browsers, audio might not be supported
    const isVoiceSupported = await voiceButton.isVisible();
    
    if (isVoiceSupported) {
      // Verify voice button is present and enabled
      await expect(voiceButton).toBeVisible();
      await expect(voiceIndicator).toBeVisible();
      
      // Verify button has correct initial state
      await expect(voiceButton).toHaveText('üé§ Voice');
      await expect(voiceButton).toBeEnabled();
      
      // Verify placeholder text mentions voice input
      const textarea = page.locator('textarea');
      await expect(textarea).toHaveAttribute('placeholder', /voice input/i);
      
      console.log('‚úÖ Voice input features detected and working');
    } else {
      // In headless/CI environments, voice might not be supported
      console.log('‚ÑπÔ∏è Voice input not supported in this environment (expected in headless browsers)');
      
      // Verify text input still works perfectly
      const textarea = page.locator('textarea');
      await expect(textarea).toBeVisible();
      await expect(textarea).toBeEnabled();
    }
  });

  test('voice input gracefully handles unsupported environments', async ({ page }) => {
    // Navigate to chat page
    await page.goto(`${process.env.E2E_URL}/chat`);
    await page.waitForTimeout(3000);
    
    // Verify that regardless of voice support, text input always works
    const textarea = page.locator('textarea');
    const sendButton = page.locator('button:has-text("Send")');
    
    await expect(textarea).toBeVisible();
    await expect(textarea).toBeEnabled();
    await expect(sendButton).toBeVisible();
    
    // Test that we can always fall back to text input
    const testMessage = 'Text input fallback test';
    await textarea.fill(testMessage);
    await expect(sendButton).toBeEnabled();
    
    // Verify the message appears in the textarea
    await expect(textarea).toHaveValue(testMessage);
    
    console.log('‚úÖ Text input fallback working correctly');
  });

  test('speech-to-text server action handles file upload correctly', async ({ page }) => {
    // This test verifies the server-side transcription functionality
    // by directly testing the API endpoint behavior
    
    await page.goto(`${process.env.E2E_URL}/chat`);
    await page.waitForTimeout(2000);
    
    // Test that the transcription endpoint exists and handles errors properly
    // We'll simulate what happens when audio recording fails or succeeds
    
    const response = await page.evaluate(async () => {
      // Create a mock audio file (empty blob to test error handling)
      const mockAudioBlob = new Blob([''], { type: 'audio/webm' });
      const formData = new FormData();
      formData.append('audio', mockAudioBlob, 'test.webm');
      
      try {
        // This will test our server action's error handling
        // Since we're sending an empty/invalid audio file
        const result = await fetch('/api/transcribe', {
          method: 'POST',
          body: formData
        });
        
        return {
          status: result.status,
          ok: result.ok
        };
      } catch (error) {
        return {
          error: error instanceof Error ? error.message : 'Unknown error',
          clientSideError: true
        };
      }
    });
    
    // The server should handle the request (even if the audio is invalid)
    // This verifies our error handling is working
    console.log('üì° Transcription endpoint response:', response);
    
    // Verify the UI elements are present for voice functionality
    const textarea = page.locator('textarea');
    await expect(textarea).toBeVisible();
    
    // Check if voice button appears (depends on browser support)
    const voiceButton = page.locator('button:has-text("üé§ Voice")');
    const hasVoiceSupport = await voiceButton.isVisible();
    
    if (hasVoiceSupport) {
      console.log('‚úÖ Voice UI elements present and ready');
    } else {
      console.log('‚ÑπÔ∏è Voice not supported in test environment (expected)');
    }
  });
});
